{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 機器學習作業\n",
    "\n",
    "1. 資料來源：[https://www.kaggle.com/competitions/boston20200827/](https://www.kaggle.com/competitions/boston20200827/)\n",
    "2. 要求：\n",
    "- 完整的機器學習預測流程,包括:資料前處理、視覺化、模型訓練、預測、結果評估等。\n",
    "- 至少使用兩種模型並比較其效果。\n",
    "\n",
    "## 資料欄位說明\n",
    "\n",
    "| 欄位      | 說明                                           |\n",
    "|-----------|------------------------------------------------|\n",
    "| ID        | 資料的唯一識別碼。                             |\n",
    "| CRIM      | 每人均犯罪率。                                 |\n",
    "| ZN        | 佔地面積超過 25,000 平方英尺的住宅用地比例。   |\n",
    "| INDUS     | 每鎮非零售業務用地的比例。                     |\n",
    "| CHAS      | 查爾斯河虛擬變數（= 1 如果地段鄰近河流；否則為 0）。|\n",
    "| NOX       | 一氧化氮濃度（每 10 百萬分之一）。             |\n",
    "| RM        | 每棟住宅的平均房間數。                         |\n",
    "| AGE       | 1940 年之前建造的自住單位比例。                 |\n",
    "| DIS?      | 到波士頓五個就業中心的加權平均距離。           |\n",
    "| RAD       | 到放射狀公路的可達性指數。                     |\n",
    "| TAX       | 每 10,000 美元的房產稅率。                     |\n",
    "| PTRATIO   | 每個城鎮的學生與教師比例。                     |\n",
    "| B 1000    | 1000(Bk - 0.63)^2，其中 Bk 是鎮上黑人比例。    |\n",
    "| LSTAT     | 低收入人口的比例（百分比）。                   |\n",
    "| PRICE     | 自住單位的中位數價格（以千美元計）。           |\n",
    "\n",
    "\n",
    "推測自：\n",
    "\n",
    "[https://www.kaggle.com/competitions/boston-dataset/data?select=boston_data.csv](https://www.kaggle.com/competitions/boston-dataset/data?select=boston_data.csv)\n",
    "\n",
    "[https://www.kaggle.com/datasets/altavish/boston-housing-dataset/data](https://www.kaggle.com/datasets/altavish/boston-housing-dataset/data)\n",
    "\n",
    "\n",
    "### 我的發現\n",
    "\n",
    "搞了一堆有的沒的都是負優化，最後決定只對資料做 StandardScaler，這是我能找出來的最好的結果。\n",
    "\n",
    "嘗試過：\n",
    "\n",
    "- 共線性特徵移除其一\n",
    "- 移除 'ID', 'CHAS' 欄位，邏輯上不應該影響房價\n",
    "- SelectKBest: k=2~13 都試過\n",
    "- z-score 移除離群值\n",
    "\n",
    "## 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T09:39:03.290422Z",
     "start_time": "2024-07-27T09:39:03.288230Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T09:39:03.309744Z",
     "start_time": "2024-07-27T09:39:03.291088Z"
    }
   },
   "outputs": [],
   "source": [
    "Boston_train_df = pd.read_csv(r'./boston20200827/Boston_train.csv')\n",
    "Boston_test_df = pd.read_csv(r'./boston20200827/Boston_test.csv')\n",
    "df = pd.concat([Boston_train_df, Boston_test_df], sort=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c558df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 資料視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how data is distributed for every column\n",
    "\n",
    "plt.figure(figsize = (20, 15))\n",
    "plotnumber = 1\n",
    "\n",
    "for column in df:\n",
    "    if plotnumber <= 14:\n",
    "        ax = plt.subplot(3, 5, plotnumber)\n",
    "        sns.histplot(df[column])\n",
    "        plt.xlabel(column, fontsize = 15)\n",
    "        \n",
    "    plotnumber += 1\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T09:39:27.627401Z",
     "start_time": "2024-07-27T09:39:03.338091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting `Price` with remaining columns\n",
    "\n",
    "plt.figure(figsize = (20, 15))\n",
    "plotnumber = 1\n",
    "\n",
    "for column in df:\n",
    "    if plotnumber <= 14:\n",
    "        ax = plt.subplot(3, 5, plotnumber)\n",
    "        sns.scatterplot(x = df['PRICE'], y = df[column])\n",
    "        \n",
    "    plotnumber += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T09:39:27.777432Z",
     "start_time": "2024-07-27T09:39:27.628103Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.displot(df['PRICE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T09:39:28.692604Z",
     "start_time": "2024-07-27T09:39:27.778203Z"
    }
   },
   "outputs": [],
   "source": [
    "# looking for outliers using box plot\n",
    "\n",
    "plt.figure(figsize = (20, 8))\n",
    "sns.boxplot(data = df, width = 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T09:39:28.697246Z",
     "start_time": "2024-07-27T09:39:28.693454Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "模型的目標是預測房價（PRICE），因此缺少目標值的數據對於訓練模型來說是沒有意義的。\n",
    "\n",
    "這些缺失目標值的樣本無法提供有用的信息來幫助模型學習，因此應該將它們從訓練數據中移除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T09:39:28.702137Z",
     "start_time": "2024-07-27T09:39:28.697929Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['PRICE'])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['PRICE'], axis=1)\n",
    "y = df['PRICE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8877c5",
   "metadata": {},
   "source": [
    "### 異常值處理\n",
    "\n",
    "There are some outliers in data.\n",
    "\n",
    "標準化（Standardization）可以在一定程度上減少離群值對數據的影響，因為它將數據縮放到一個相對一致的範圍內。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3fc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e8e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 8))\n",
    "sns.boxplot(data = X_scaled, width = 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15aca45",
   "metadata": {},
   "source": [
    "#### Z-Score 移除異常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b91275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # 計算 Z-score\n",
    "# z_scores = np.abs((X_scaled - X_scaled.mean()) / X_scaled.std())\n",
    "\n",
    "# # 設定 Z-score 閾值，通常為 3\n",
    "# threshold = 3\n",
    "# outliers = np.where(z_scores > threshold)\n",
    "\n",
    "# # 移除異常值\n",
    "# X_clean = np.delete(X_scaled, outliers[0], axis=0)\n",
    "# y_clean = np.delete(y, outliers[0], axis=0)\n",
    "\n",
    "# plt.figure(figsize = (20, 8))\n",
    "# sns.boxplot(data = X_clean, width = 0.8)\n",
    "# plt.show()\n",
    "\n",
    "# X_scaled = X_clean\n",
    "# y = y_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec16fe",
   "metadata": {},
   "source": [
    "### 檢查多重共線性\n",
    "\n",
    "- 不穩定的係數估計：當自變數之間高度相關時，回歸係數的估計值會變得不穩定，可能會出現很大的標準誤差。\n",
    "- 解釋困難：高度相關的自變數使得很難確定哪個變數對應變數有實質性的影響。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4092c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for multicollinearity using `VIF` and `correlation matrix`\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "\n",
    "vif['VIF'] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "vif['Features'] = X.columns\n",
    "\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16, 8))\n",
    "sns.heatmap(df.corr(), annot = True, fmt = '1.2f', annot_kws = {'size' : 10}, linewidth = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27c7113",
   "metadata": {},
   "source": [
    "RAD 和 TAX 之間的相關性很高，因此我們可以考慮移除其中一個變數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ecc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'RAD' column from data\n",
    "\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# X_scaled_df = X_scaled_df.drop(columns=['RAD'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf025aa",
   "metadata": {},
   "source": [
    "#### SelectKBest\n",
    "\n",
    "用途：選擇K個最好的特徵，並且可以通過設置不同的參數來選擇不同的特徵選擇方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d38559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# selectkbest = SelectKBest(k=5)\n",
    "# X_scaled = selectkbest.fit_transform(X_scaled, y)\n",
    "\n",
    "# # combine thsese two arrays\n",
    "# print('Selected features: {}'.format(X.columns[selectkbest.get_support()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907043b8",
   "metadata": {},
   "source": [
    "## 拆分訓練集和測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size = 0.30, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b6aedd",
   "metadata": {},
   "source": [
    "## 開始訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec27f0b",
   "metadata": {},
   "source": [
    "### 模型：Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# 使用驗證集進行預測\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "# 結果可視化\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test.values, marker='o', label='Actual Price')\n",
    "plt.plot(y_pred, marker='x', label='Predicted Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# test accuracy of the model\n",
    "print('Accuracy of the model:', lm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122a294",
   "metadata": {},
   "source": [
    "## 評估模型的好壞\n",
    "\n",
    "### 回歸模型的評估指標\n",
    "\n",
    "1. **MSE (Mean Squared Error) - 均方誤差**\n",
    "\n",
    "   - **解釋**：MSE 是預測值與真實值之間平方誤差的平均值。它反映了模型預測誤差的平方平均值。\n",
    "   - **意義**：MSE 對於較大的誤差更加敏感，因為誤差被平方了。MSE 越小，表示模型的預測越準確。\n",
    "\n",
    "2. **MAE (Mean Absolute Error) - 平均絕對誤差**\n",
    "\n",
    "   - **解釋**：MAE 是預測值與真實值之間絕對誤差的平均值。\n",
    "   - **意義**：MAE 是一個容易解釋的指標，因為它表示了平均預測誤差的實際值。MAE 越小，表示模型的預測越準確。\n",
    "\n",
    "3. **RMSE (Root Mean Squared Error) - 均方根誤差**\n",
    "\n",
    "   - **解釋**：RMSE 是 MSE 的平方根，提供了一個與原始數據單位相同的誤差指標。\n",
    "   - **意義**：RMSE 與 MSE 類似，但由於它取了平方根，因此與原始數據的尺度一致。RMSE 越小，表示模型的預測越準確。\n",
    "\n",
    "4. **MAPE (Mean Absolute Percentage Error) - 平均絕對百分比誤差**\n",
    "\n",
    "   - **解釋**：MAPE 是預測值與真實值之間相對誤差的平均值，通常以百分比表示。\n",
    "   - **意義**：MAPE 提供了預測誤差的相對尺度，這對於不同量級的數據特別有用。MAPE 越小，表示模型的預測越準確。\n",
    "\n",
    "#### 綜合理解：\n",
    "- **MSE** 和 **RMSE** 對於較大的誤差更加敏感，因此它們能夠突出模型在大誤差情況下的性能。\n",
    "- **MAE** 提供了一個直觀的平均誤差值，易於解釋和理解。\n",
    "- **MAPE** 提供了預測誤差的相對尺度，特別適合於不同量級的數據比較。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4acaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "print('MSE(Mean Square Error):',mean_absolute_error(y_test,y_pred)) #計算 MAE\n",
    "print('MAE(Mean Absolute Error):',mean_squared_error(y_test,y_pred)) #計算 MSE\n",
    "print('RMSE(Root Mean Square Error):',np.sqrt(mean_squared_error(y_test,y_pred))) #計算 RMSE\n",
    "print('MAPE(Mean Absolute Percentage Error):',mean_absolute_percentage_error(y_test,y_pred)) #計算 MAPE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e20f848",
   "metadata": {},
   "source": [
    "### Defining function for regression metrics\n",
    "\n",
    "#### 1. R² Score (R平方值)\n",
    "**用途與意義**：\n",
    "- **用途**：R² Score 是用來衡量模型解釋變數之間變異程度的指標。它表示自變量（輸入變量）能解釋的應變量（輸出變量）總變異的比例。\n",
    "- **意義**：R² 的值介於 0 和 1 之間。值越接近 1，表示模型越能解釋應變量的變異；值接近 0，表示模型解釋能力很低。具體來說，R² 值為 0.8 表示模型解釋了 80% 的應變量變異。\n",
    "\n",
    "#### 2. Adjusted R² Score (調整後的 R平方值)\n",
    "**用途與意義**：\n",
    "- **用途**：Adjusted R² Score 是對 R² Score 的修正，考慮了模型中變數數量的影響。它用於比較不同複雜度的模型，特別是當模型包含多個自變量時。\n",
    "- **意義**：Adjusted R² 可以防止過度擬合（overfitting），因為它會隨著不相關變數的加入而減少。它的計算方式調整了變數數量的影響，提供更準確的模型解釋能力評估。\n",
    "\n",
    "#### 3. Cross Validated R² Score (交叉驗證 R平方值)\n",
    "**用途與意義**：\n",
    "- **用途**：Cross Validated R² Score 是通過交叉驗證技術計算的 R² Score，旨在評估模型在未見數據上的表現。\n",
    "- **意義**：這個指標能夠提供模型在不同數據集上的穩定性評估，減少過度擬合的風險。透過 K-fold 交叉驗證等方法，可以更可靠地估計模型的泛化能力。\n",
    "\n",
    "#### 4. RMSE (Root Mean Squared Error, 均方根誤差)\n",
    "**用途與意義**：\n",
    "- **用途**：RMSE 是用來衡量模型預測值與實際值之間差異的指標。它表示預測誤差的標準差。\n",
    "- **意義**：RMSE 的值越小，表示模型預測的準確性越高。它對大誤差較為敏感，因為誤差是平方後再取平均值。RMSE 提供了預測誤差的絕對量度，是評估模型預測準確性的重要指標。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def Reg_Models_Evaluation_Metrics (model,X_train,y_train,X_test,y_test,y_pred):\n",
    "    cv_score = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10)\n",
    "    \n",
    "    # Calculating Adjusted R-squared\n",
    "    r2 = model.score(X_test, y_test)\n",
    "    # Number of observations is the shape along axis 0\n",
    "    n = X_test.shape[0]\n",
    "    # Number of features (predictors, p) is the shape along axis 1\n",
    "    p = X_test.shape[1]\n",
    "    # Adjusted R-squared formula\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    R2 = model.score(X_test, y_test)\n",
    "    CV_R2 = cv_score.mean()\n",
    "\n",
    "    return R2, adjusted_r2, CV_R2, RMSE\n",
    "    \n",
    "    print('RMSE:', round(RMSE,4))\n",
    "    print('R2:', round(R2,4))\n",
    "    print('Adjusted R2:', round(adjusted_r2, 4) )\n",
    "    print(\"Cross Validated R2: \", round(cv_score.mean(),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = [Reg_Models_Evaluation_Metrics(lm,X_train,y_train,X_test,y_test,y_pred)]\n",
    "\n",
    "lm_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])\n",
    "lm_score.insert(0, 'Model', 'Linear Regression')\n",
    "lm_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13a771",
   "metadata": {},
   "source": [
    "## 模型：Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd582ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Creating and training model\n",
    "RandomForest_reg = RandomForestRegressor(n_estimators = 10, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_reg.fit(X_train, y_train)\n",
    "# Model making a prediction on test data\n",
    "y_pred = RandomForest_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = [Reg_Models_Evaluation_Metrics(RandomForest_reg,X_train,y_train,X_test,y_test,y_pred)]\n",
    "\n",
    "rf_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])\n",
    "rf_score.insert(0, 'Model', 'Random Forest')\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf23f56",
   "metadata": {},
   "source": [
    "## 模型：Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c65f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Creating and training model\n",
    "ridge_reg = Ridge(alpha=3, solver=\"cholesky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5265614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg.fit(X_train, y_train)\n",
    "# Model making a prediction on test data\n",
    "y_pred = ridge_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = [Reg_Models_Evaluation_Metrics(ridge_reg,X_train,y_train,X_test,y_test,y_pred)]\n",
    "\n",
    "rr_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])\n",
    "rr_score.insert(0, 'Model', 'Ridge Regression')\n",
    "rr_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047db82f",
   "metadata": {},
   "source": [
    "## 模型：XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# create an xgboost regression model\n",
    "XGBR = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.8, colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ed7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBR.fit(X_train, y_train)\n",
    "# Model making a prediction on test data\n",
    "y_pred = XGBR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = [Reg_Models_Evaluation_Metrics(XGBR,X_train,y_train,X_test,y_test,y_pred)]\n",
    "\n",
    "XGBR_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])\n",
    "XGBR_score.insert(0, 'Model', 'XGBoost')\n",
    "XGBR_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298dab0",
   "metadata": {},
   "source": [
    "## 模型：Recursive Feature Elimination (RFE)\n",
    "\n",
    "RFE is a wrapper-type feature selection algorithm. This means that a different machine learning algorithm is given and used in the core of the method, is wrapped by RFE, and used to help select features.\n",
    "\n",
    "Random Forest has usually good performance combining with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=RandomForestRegressor(), n_features_to_select=60)\n",
    "model = RandomForestRegressor()\n",
    "rf_pipeline = Pipeline(steps=[('s',rfe),('m',model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline.fit(X_train, y_train)\n",
    "# Model making a prediction on test data\n",
    "y_pred = rf_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = [Reg_Models_Evaluation_Metrics(rf_pipeline,X_train,y_train,X_test,y_test,y_pred)]\n",
    "\n",
    "rfe_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])\n",
    "rfe_score.insert(0, 'Model', 'Random Forest with RFE')\n",
    "rfe_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e6bfe",
   "metadata": {},
   "source": [
    "# 結果比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceed3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat([rfe_score, XGBR_score, rr_score, rf_score, lm_score], ignore_index=True, sort=False)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276aaa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axe = plt.subplots(1,1, figsize=(18,6))\n",
    "\n",
    "predictions.sort_values(by=['Cross Validated R2 Score'], ascending=False, inplace=True)\n",
    "\n",
    "sns.barplot(x='Cross Validated R2 Score', y='Model', data = predictions, ax = axe)\n",
    "axe.set_xlabel('Cross Validated R2 Score', size=16)\n",
    "axe.set_ylabel('Model')\n",
    "axe.set_xlim(0,1.0)\n",
    "\n",
    "axe.set(title='Model Performance')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
